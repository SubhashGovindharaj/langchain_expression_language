# ğŸ§  LangChain Expression Language App (FastAPI + Ollama + LangSmith)

This project demonstrates the use of **LangChain Expression Language (LCEL)** to build a local LLM app using **FastAPI** and **Ollama's llama3** model. It includes **LangSmith** integration for experiment tracking and chain observability.

---

## ğŸš€ Features

- ğŸ§© LangChain Expression Language (LCEL)
- ğŸ¤– Local LLM with Ollama (`llama3`)
- ğŸ” LangSmith tracing enabled
- âš¡ FastAPI backend with LangServe
- ğŸ” Environment variable management using `python-dotenv`

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/SubhashGovindharaj/langchain_expression_language.git
cd langchain_expression_language

---

### âœ… `requirements.txt`

```txt
langchain
langchain-core
langchain-community
langserve
ollama
fastapi
uvicorn
sse-starlette
python-dotenv
